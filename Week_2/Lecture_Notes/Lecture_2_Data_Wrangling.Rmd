---
title: "Data_Wrangling_Visualization"
output: pdf_document
date: "2025-03-03"
---

### In Today's Lecture We Will Learn...

1) Generating Random Data

2) Adding and Removing Rows and Columns

3) String Manipulation

4) Wide and Long Format Data Frames

5) Basic Plotting in R

6) ggplot2 Figures

7) Reading in Public Data

8) Adding Statistics to Figures

9) Saving Figures

10) Generating Summary Statistics

### Generating Random Data
In our previous lesson we learned about data structures, in particular we learned about data frames. As a refresher, data frames are two-dimensional structures that can hold different data types. Due to it's flexibility, data frames are a very popular way in which Data Scientists store information. 

Today we will be dipping our toes into generating our own random data and working with that data in a data frame structure to begin data wrangling and gain a clear understanding of randomness, distributions, and sampling. While generating our own random data may initially appear to be a silly task, these hypothetical data sets aid us in exploring different scenarios, which is particularly useful in statistics, machine learning, and research. In fact, many authors make use of self-generated data to test tools they build for research, espcailly if data is not readily available. 

All that said, let's start generating some random data using the R functions `rnorm()` and `rbinom()`. `rnorm()`generate random data taken from a normal distribution. You can specify the number of digits that you need as well as the mean and standard deviation of your your data. Similarly, `rbinom()` generates values from a binomial distribution. Users can specify `size`, the number of trials, and `prob`, the probability of success on each trial. 

Here are a few examples for the normal distributions:
```{r}
rnorm(10, mean = 0, sd = 1)
```
```{r}
rnorm(10, mean = 10, sd = 2)
```
Here are a few examples for the binomial distributions:

```{r}
rbinom(10, 8, 0.5)
```
```{r}
rbinom(10, 1, 0.5)
```

Now, you may notice that you and your class buddy don't get the same values. What gives? You have the exact same code. This is simply the nature of the random number generation in R. Each time we call `rnorm()`, R produces a different set of random values drown from a normal distribution. Let's say, for consistency sake, we want to keep our values the same as our class buddy's. To do this, we can set a seed. Setting a seed ensures that every time you run the code, the exact same sequence of random numbers is generated. This is crucial for reproducibility in research, where you want others to be able to verify and replicate your results. So let's set a seed and then compare our results to those of our buddy's results.

Here is an example setting a seed and generating normally distributed random data:
```{r}
set.seed(246)
rnorm(10, mean = 3, sd = 1)
```

And here is an example setting a seed and generating binomial random data:

```{r}
set.seed(246)
rbinom(10, 1, 0.5)
```

Now that we have gotten our feet wet generating random data, let's put these skills to use and generate some random meta data we can use to further develop our data wrangling skills. 

```{r}
# Load necessary libraries
library(dplyr)

# Set the seed for reproducibility
set.seed(123)

# Define the number of samples
n <- 100  # You can change this number to generate more or fewer samples

# Generate random data
random_data <- data.frame(
  Subject_ID = paste("Subject", 1:n, sep = "_"),  # Generate Subject IDs
  Age = pmax(18, pmin(85, round(rnorm(n, mean = 50, sd = 10)))),  # Random ages between 18 and 85
  Sex = sample(c("Male", "Female"), n, replace = TRUE),  # Random sex values
  Disease_Status = sample(c("Case", "Control"), n, replace = TRUE),  # Random disease status
  Heart_Rate = pmax(40, pmin(200, round(rnorm(n, mean = 75, sd = 15))))  # Random heart rates between 40 and 200
)

# View the first few rows of the generated dataset
head(random_data)
```

In the above code we have created a data frame called `random_data` that contains five columns: Subject_ID, Age, Sex, Disease_Status, and Heart_Rate. Let's breakdown how we have generated the data in each column:

  * Subject_ID: Using the `paste` function we have combined together the word "Subject" with numbers 1 through 100 and separated "Subject" and the number with a "_". 
  * Age: The use of `pmax` and `pmin` ensure that the values fall between 18 and 85 for age. We then use `rnorm` to generate a set of 100 ages with a mean of 50 and a standard deviation of 10 years.
  * Sex: This variable is generated by providing values we would like included in our column, in this case, "Male" and "Female". We then employ the `sample()` function to sample "Male" or "Female" `n` times with replacement, meaning if we take "Male" out of the bag, it can be selected again during the next round of sampling. 
  * Disease Status: We sampled "Cases" and "Controls" in the same manner in which we sampled "Males" and "Females".
  * Heart_Rate: The use of `pmax` and `pmin` ensure that the values fall between 40 and 200 for hear rate. We then use `rnorm` to generate a set of 100 ages with a mean of 75 and a standard deviation of 15 years.

### Adding and Removing Rows and Columns

We may find it necessary to add information to our data frames. For example, we might want to add a column for "Alcohol Consumption". To do this, we can use the function `cbind()`. `cbind()` takes a vector and adds that vector as a column to your data frame. Let's try this out on our randomly generated data. 

```{r}
# Number of participants
n=100

# Generate vector to add as a column
Alcohol_Consumption = sample(c("Yes", "No"), n, replace = TRUE)

# Add the column
random_data <- cbind(random_data, Alcohol_Consumption)

# View after adding the column
print(head(random_data))
```
We can also add all the information for one participant to this data frame using `rbind()`. Take a look at the code below to see an example of this:

```{r}
# Generate a vector of data to add
participant_101 <- c("Subject_101","37","Female","Case","82","No")

# Add row
random_data <- rbind(random_data, participant_101)

# Visualize output
tail(random_data)
```

Just as we can add rows and columns, we can remove them using either the names of the columns or rows or the indices. Let's say we want to get rid of the "Alcohol_Consumption" and "Sex" columns in our data frame. To do this we can 

```{r}
# Remove using index
random_data <- random_data[,-6]

# Remove using column name
random_data <- subset(random_data, select = -c(Sex))

# Visualize after removal
head(random_data)
```
We can remove rows using the code below:

```{r}
# Remove using the index 
random_data <- random_data[-1,]

# Remove using the name of the row 
random_data <- random_data[!row.names(random_data) %in% "5",]

# Visualize after removal
head(random_data)
```

### String Manipulation
Above we have successfully generated random data, but what if we want to change a something about the data we input? Specifically, I might want to change the word "Subject" in "Subject_ID" to "Participant". To do this we can implement string manipulation with functions `gsub()` and `sub()`. These two functions will substitute strings or characters in a vector or a data frame with a specific string. Let's take a look at how to use these functions on our random data. 

```{r}
## Exchange the word "Subject" for "Participant" in our "Subject_ID" column
random_data$Subject_ID <- gsub("Subject", "Participant", random_data$Subject_ID)

## Visualize the data frame
head(random_data)
```
After visualizing the data frame you will see that the word "Subject" has been replaced with "Participant". This functionality is really useful when you need to pick apart a more complex string. Let's take a look at the example below. Here we are subsetting this sentence using `sub()` to return everything in the string before the third "_" character.

```{r}
my_string <- "Hello_Everyone_And_Welcome_To_Foundations_of_Data_Science!"
my_string_sub <- sub("^(([^_]*_){2}[^_]*)_.*", "\\1", my_string)

print(my_string_sub)
```

You can use string manipulation for a number of operations in data cleaning, feature engineering, data integration and merging, text analysis, and natural language processing. 

### Wide vs. Long Format
Up until now, we have been working with what is referred to as a "wide" format data frame. This is the type of data frame most of us are likely familiar with from classes and work. Each subject or observational unit in a wide form data frame has a single row. Different variables, like age and sex, are stored in separate columns. Wide format is useful for comparing observational units, in our case, the subjects in our study. 

A second type of data frame format is a "long" format. In a "long" format data frame each observation or measurement has its own row. Typically, we will ave columns identifying the subject and then the values. While this is not a data format that that us humans like to work with, many R packages and functions require that your data be in "long" format. Let's convert our "wide" form data from into a "long" form using the R package `tidyr`.

```{r}
# Read in library
library(tidyr)

# Convert from wide to long format
random_data_age_sex <- tidyr::pivot_longer(random_data,cols=c("Age","Heart_Rate"))

# Visualize after conversion
head(random_data_age_sex)
```
Similarly, to convert from "long" format back to "wide" format, we can use the tidyr `pivot_wider()` function. 

```{r}
# Convert from long to wide
random_data_age_sex_wide <- tidyr::pivot_wider(random_data_age_sex)

# Visualize after converting from long to wide
head(random_data_age_sex_wide)
```
Now that we have gotten the hang of data frame manipulation, let's begin to generate some basice plots in R. 

### Basic Plotting in R

One really handy thing to do when you are handed a new data set is to generate a few figures that help you get an idea of how the data is distributed. Base R has built in functions to generate simple plots such as histograms, scatter plots, and box plots among others. Using the data frame we generated above, let's create a histogram displaying the distribution of subject heart rate using the base R function `hist()`.

```{r}
hist(random_data$Heart_Rate)
```
Above we have generated a histogram displaying heart rate from our random data, but the x and y-axes are messy, as is the title. Let's clean these up using the `main`, `xlab`, and `ylab` parameters that can be applied to `hist`.

```{r}
hist(random_data$Heart_Rate, main = "Distribution of Heart Rate", 
     xlab = "Heart Rate", 
     ylab = "Freq")
```
There, much prettier! But we might want to see more granularity in the distribution. In order to do this, we can make chop up the bars in the histogram using the `breaks` argument. Lets try 10, 20, and 30 breaks to develop a feel for changes in the distribution. 

```{r}
hist(random_data$Heart_Rate, main = "Distribution of Heart Rate", 
     xlab = "Heart Rate", 
     ylab = "Freq",
     breaks = 10)
```
```{r}
hist(random_data$Heart_Rate, main = "Distribution of Heart Rate", 
     xlab = "Heart Rate", 
     ylab = "Freq",
     breaks = 20)
```
```{r}
hist(random_data$Heart_Rate, main = "Distribution of Heart Rate", 
     xlab = "Heart Rate", 
     ylab = "Freq",
     breaks = 30)
```
When we apply additional breaks to our data we begin to see the finer shifts in the distribution. 

In addition to histograms, we can use base R functions to generate scatter plots. Let's say we want to generate a scatter plot of age vs. heart rate to observe if any treads could possibly exist between the two variables. To create a scatter plot, we can employ the `plot()` function in R. 

```{r}
plot(random_data$Age, random_data$Heart_Rate, main = "Age vs. Heart Rate", xlab = "Age", ylab = "Heart Rate")
```
Perhaps we are instead interested in observing if there are any differences in heart rate between cases and controls. A box plot would be appropriate to visualize differences between cases and controls. Let's use base R to generate one box plot for the heart rate of "cases" and another box plot for "controls" in our self-generated data.

```{r}
boxplot(Heart_Rate ~ Disease_Status, data = random_data, frame = FALSE, main = "Box Plots of Heart Rate \nby Disease Status", xlab = "Disease Status", ylab = "Heart Rate")
```
Now, I typically use base R to just to get a quick look at the distribution of my data and any potentially interesting trends. I wouldn't consider these base R plots to be publication ready. To produce attractive-looking figures for publications or work presentations, I would encourage you to use ggplot2, an R package that is uniquely suited to figure generation.

### ggplot2 Figures
ggplot2 is an R package for data visualization that allows users to create a wide variety of plots in a structured and layered approach. You have more freedom to customize your plots, add details, and group plots to communicate a point you are trying to make. Like in base R, you can create basic plots like box plots, but you cn also generate line, violin, and bubble plots. Let's once again use our random data to generate some interesting ggplot2 plots. 

Let's say we want to generate some box plots for heart rate, but we want to visualize the distributions by Sex and Disease_Status. To do this we can create a grouped box plot. Here is some code that we can use to generate this visualization:

```{r}
library(ggplot2)


ggplot(random_data, aes(x = Sex, y = Heart_Rate, fill = Disease_Status)) +
  geom_boxplot() +
  labs(x = "Sex", y = "Heart Rate", fill = "Disease Status", 
       title = "Heart Rate Distribution \nby Sex and Disease Status") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")  # Adjust colors if needed

```
Wow! This is looking really cool! We can also add a jitter over these box plots. A jitter simply displays each of our data points. Here is some code to achieve this:

```{r}
ggplot(random_data, aes(x = Sex, y = Heart_Rate, fill = Disease_Status)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7, position = position_dodge(width = 0.75)) +
  geom_jitter(aes(color = Disease_Status), position = position_dodge(width = 0.75), 
              size = 2, alpha = 0.6) +
  labs(x = "Sex", y = "Heart Rate", fill = "Disease Status", color = "Disease Status",
       title = "Heart Rate Distribution \nby Sex and Disease Status") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1")
```

ggplot2 has a suite of built in functions to generate all sorts of funky looking plots to visualize our data including rain cloud plots. Take a look at the plot generated by the code below. This rain cloud plot provides us a bit more detail with a half violin plot, thereby further visualizing the distribution of the data by Disease_Status. 

```{r}
library(ggdist)

ggplot(random_data, aes(x = Sex, y = Heart_Rate, fill = Disease_Status)) +
  stat_halfeye(aes(color = Disease_Status), position = position_dodge(width = 0.75), alpha = 0.6) + 
  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75), outlier.shape = NA, alpha = 0.7) +  
  geom_jitter(aes(color = Disease_Status), position = position_dodge(width = 0.75), size = 1.5, alpha = 0.6) +  
  theme_minimal() +
  labs(title = "Raincloud Plot: Heart Rate by Sex & Disease Status") +
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1")
```
Perhaps you are interested in displaying your data more simply with a "bee swarm" plot, like the one below. 
```{r}
library(ggbeeswarm)

ggplot(random_data, aes(x = Sex, y = Heart_Rate, color = Disease_Status)) +
  geom_quasirandom(dodge.width = 0.75, size = 2, alpha = 0.7) +
  theme_minimal() +
  labs(title = "Beeswarm Plot: Heart Rate by Sex & Disease Status") +
  scale_color_brewer(palette = "Set1")
```
I encourage you to take a look at the ggplot2 documentation, online tutorials, and videos to get a better idea of all the data visualization possibilities with ggplot2! Also take some time to have a conversation with good ol' ChatGPT about what visualizations might be appropriate for your data. 

### Reading in Public Data
So far in this demonstration, we have generated our own data, but more often you will be dealing with data generated from an study you conducted or you will be pulling data from publicly available sources. Let's check out a page I often visit to pillage for data, [GEO](https://www.ncbi.nlm.nih.gov/geo/). GEO or Gene Expression Omnibus is a genomics repository where all sorts of sequencing data is available for download. Pull up any scientific article that contains 'omics data and you will likely find in the "Data Availability" section a GEO accession number begins with "GSE...". Entering that accession number into the GEO data base will bring you to that study's page containing all the raw and processed data associated with those experiments. Today we will be taking a peek at the raw count data associated with this study: [Synovial inflammatory pathways characterize anti-TNF-responsive rheumatoid arthritis patients](https://acrjournals.onlinelibrary.wiley.com/doi/full/10.1002/art.42295)(2022). The GEO accession number for this data is GSE198520. From this GEO page I have downloaded the raw counts and meta data from this study investigating the mechanistic basis of response to anti-tumor necrosis factor (anti-TNF) biologics in rheumatoid arthritic (RA) patients. The files can be found in out Week 2 "data" directory on my GitHub and on the Canvas page. The study contains RNA-seq data of synovial tissue from 46 RA patients before and after 12 weeks of anti-TNF treatment. Let's read in the count matrix containing the raw RNA-seq data:

```{r}
## Change this file path to the path for the data on your local machine
file_path <- "/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_2/data/"

## Use read.delim to read in this data
ra_data <- read.delim(paste0(file_path, "GSE198520_Raw_gene_count_matrix.txt"), row.names = 1)
ra_df <- data.frame(ra_data)

## Visualize the data frame
print(head(ra_df))
```
Neat! It looks like we have 92 samples, which checks out because we have 46 RA patients and one time point before treatment and one after treatment. How many genes are included in this data? We can check the dimensions of the data frame for that.

```{r}
dim(ra_df)
```
We have 19187 genes in this data frame. I say we check out the meta data associated with this project. That data is located in the metadata.csv file I have provided for you in the data directory.

```{r}
## Read in the file using read.csv()
metadata <- read.csv(paste0(file_path,"metadata.csv"), row.names = 1)

## I just like to make sure everything is a data frame when I read it in
metadata <- data.frame(metadata)

## Visualize the contents of the file
head(metadata)
```
There is some really interesting meta data in this file that we can use to generate attractive figures like the ones we generated with using our sel-generated data. In particular, let's take a look at the expression of IL6 pre and post treatment with a TNF-alpha inhibitor. 

```{r}
## Fetch TNFA data from the count matrix
gene_data <- ra_df[c("CXCL13","STAT3","ACTA2"),]

## Transpose the data
gene_data <- t(gene_data)

## Bind the IL6 data to the meta data 
gene_metadata <- merge(gene_data, metadata, by = 'row.names', all = TRUE)

## Move the sample names to row names and remove "Row.names"
rownames(gene_metadata) <- gene_metadata$Row.names
gene_metadata <- subset(gene_metadata, select = -c(Row.names))

## Visualize the combined data frame
head(gene_metadata)
```
Nice! Now we have a data frame containing the meta data along with the raw count data from a few genes we may find interesting. Let's make a ggplot2 box plot displaying the CXCL13 levels for the pre and post treatment time points:

```{r}
library(ggplot2)
ggplot(gene_metadata, aes(x = timepoint, y = CXCL13, fill = timepoint)) +
  geom_boxplot() +
  labs(x = "Time Point", y = "CXCL13 Count", fill = "Time Point", 
       title = "CXCL13 Count Distribution by Treatment Time Point") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")  # Adjust colors if needed
```
Hummmm seems like the distribution is sort of spread out, but is it significant?

### Adding Statistics to Figures
Many times when we are generating figures, its really helpful to add significance values from statistical tests. One way we can do this is by leveraging the `ggpubr` package which contains built in functions to implement non-parametric and parametric tests to our data. The function conveniently adds the resulting p-values to the plots. Note, we are not going to dive into the statistics in this class. For today, rest assured that a non-parametic test such as the Wilcoxon Rank Sum test is sufficient for this data. Let's do this with the box plot above.

```{r}
library(ggpubr)

p <- ggplot(gene_metadata, aes(x = timepoint, y = CXCL13, fill = timepoint)) +geom_boxplot() +
  labs(x = "Time Point", y = "CXCL13 Count", fill = "Time Point", 
       title = "CXCL13 Count Distribution by Treatment Time Point") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")

print(p + stat_compare_means(method = "wilcox"))
```
You will see at the top of our plot a p-value from a Wilcoxon Rank Sum test has appear indicating that the raw counts for CXCL13 between the pre and post treated samples is statistically significant. Let's see if this is true for the two other genes in our `gene_metadata` data frame and arrange our plots into a nice panel for ease of viewing. 

```{r}
## This library will be helpful in grid plotting
library(gridExtra)

## This is our CXCL13 plot
p1 <- ggplot(gene_metadata, aes(x = timepoint, y = CXCL13, fill = timepoint)) +geom_boxplot() +
  labs(x = "Time Point", y = "CXCL13 Count", fill = "Time Point", 
       title = "CXCL13 Count Distribution \nby Treatment Time Point") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1") + stat_compare_means(method = "wilcox", size = 3) + theme(
    text = element_text(size = 8),           # Set base text size
    axis.title = element_text(size = 8),     # Axis titles
    axis.text = element_text(size = 8),      # Axis text
    legend.title = element_text(size = 8),   # Legend title
    legend.text = element_text(size = 8),    # Legend text
    plot.title = element_text(size = 8, hjust = 0.5)  # Title (centered)
  )


## This is our ACTA2 plot
p2 <- ggplot(gene_metadata, aes(x = timepoint, y = ACTA2, fill = timepoint)) +geom_boxplot() +
  labs(x = "Time Point", y = "ACTA2 Count", fill = "Time Point", 
       title = "ACTA2 Count Distribution \nby Treatment Time Point") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1") + stat_compare_means(method = "wilcox", size = 3) + theme(
    text = element_text(size = 8),           # Set base text size
    axis.title = element_text(size = 8),     # Axis titles
    axis.text = element_text(size = 8),      # Axis text
    legend.title = element_text(size = 8),   # Legend title
    legend.text = element_text(size = 8),    # Legend text
    plot.title = element_text(size = 8, hjust = 0.5)  # Title (centered)
  )

## This is our STAT3 plot
p3 <- ggplot(gene_metadata, aes(x = timepoint, y = STAT3, fill = timepoint)) +geom_boxplot() +
  labs(x = "Time Point", y = "STAT3 Count", fill = "Time Point", 
       title = "STAT3 Count Distribution \nby Treatment Time Point") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1") + stat_compare_means(method = "wilcox", size = 3) + theme(
    text = element_text(size = 8),           # Set base text size
    axis.title = element_text(size = 8),     # Axis titles
    axis.text = element_text(size = 8),      # Axis text
    legend.title = element_text(size = 8),   # Legend title
    legend.text = element_text(size = 8),    # Legend text
    plot.title = element_text(size = 8, hjust = 0.5)  # Title (centered)
  )

grid.arrange(p1, p2, p3, ncol = 2, nrow = 2)  # Arrange in 2 columns
```
### Saving Figures
Ah, now I quiet like the figure we just generated. We can save this figure as a PDF, png, jpeg, or even a tiff. Today we will practice saving our plots as pngs. To do this we can use the R base function `png()`. 

```{r}
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_2/Figures/boxplot_panel.png", width = 2000, height = 1500, res = 300)
print(grid.arrange(p1, p2, p3, ncol = 2, nrow = 2))
dev.off()
```

In the above section of code we indicate that we want to use the `png()` function. Within this function the first parameter is the file path and name to which we would like to save our plot. The next two parameters are the height and width of the figure we would like to generate in pixels (px). Pixels are often not as intuitive as other units of measurement, so you can change the `units` parameter to `in` for inches, `cm` for centimeters, or `mm` for millimeters. The final parameter here indicates the resolution of the figure we are saving. Typically, a resolution of 300dpi should be sufficient. 

## Generating Summary Statistics
In addition to generating figures, we can also generate helpful statistics to report with our figures. One quick way to gain an understanding of the distribution of your data is to generate summary statistics using the `summary()`. This function returns the minimum, first quantile, median, mean, third quantile, and maximum of your data. R also offers options to generate a few of these statistics at a time with the functions `min()`,`max()`,`mean()`, `median()`, and even standard deviation with `sd()`.

```{r}
## Generates full summary statistics
summary(metadata$AGE)

## Minimum
min(metadata$AGE)

## Maximum
max(metadata$AGE)

## Mean
mean(metadata$AGE)

## Median
median(metadata$AGE)

## Standard Deviation
sd(metadata$AGE)
```

### Conclusions

In today's lesson we covered fundamental skills that are essential for data science. Each topic contributes to a strong foundation in data analysis, visualization, and statistical reasoning

* Generated Random Data: Simulating data is crucial for testing models, validating assumptions, and debugging code when real-world data is unavailable.

* Implemented String Manipulation: Cleaning and processing text data is a core part of data wrangling, ensuring consistency and accuracy in data sets.

* Data Frame Format Conversion: Switching between wide and long data frame formats for ease of plotting and visualization. 

* Generated Basic R Plots: Generation of quick plots is key to exploratory data analysis, helping to uncover patterns and insights in data.

* Created ggplot2 Plots: ggplot2 provides a powerful and flexible way to create high-quality visualizations that clearly convey relevant points for manuscripts or presentation. 

* Read in Publicly Available Data: Accessing and working with external datasets is a fundamental skill, allowing data scientists to analyze real-world information. 

* Added Statistics to ggplot2 Plots: Integrating statistical insights directly into visualizations enhances interpretability and decision-making.

* Calculated Summary Statistics: understanding key metrics (mean, median, standard deviation, etc.) is fundamental for data exploration and hypothesis generation.

In our next lessons we will be expanding upon these skills to automate data processing.






