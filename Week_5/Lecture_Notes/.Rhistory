# Read in necessary libraries
library(dplyr)
# Select the most important variables
Imp <- varImp(Fit1, scale = FALSE)
# Make a plot of which variables are the most important
plot(Imp, top = 25)
Imp$importance[order(-Imp$importance$Overall), ]
# Select the top 10 most important features
featSel<-head(rownames(Imp$importance %>% arrange(desc(Overall))), n=10)
# Need to put "+" between all variables
features_string <- paste(featSel, collapse = " + ")
formula_str <- paste("Class ~", features_string)
# Convert string to formula
feat_formula <- as.formula(formula_str)
# Now fit the model with the correct formula
Fit2 <- train(feat_formula, data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
Fit2
# Generate predictions
preds<-predict(Fit4,Test)
# Generate predictions
preds<-predict(Fit2,Test)
# Generate confusion matrix
cm <- confusionMatrix(preds, Test$Class, positive = "WS")
# Extract table from cm object
cm_table <- as.data.frame(cm$table)
# Plot and save heatmap with ggplot2
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/confusion_matrix_RF.png", width = 1000, height = 1000, res = 200)
print(ggplot(cm_table, aes(Prediction, Reference, fill = Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = Freq), size = 6) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = "Confusion Matrix",
x = "Predicted Class",
y = "Actual Class") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14)))
dev.off()
# Fit the model
fitControl <- trainControl(
method = "cv",
number = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
#Train the SVM model
svmFit <- train(
Class ~ .,
data = Train,
method = "svmRadial",
trControl = fitControl,
metric = "ROC",
preProcess = c("center", "scale")
)
# Results
print(svmFit)
# Generate predictions
preds<-predict(svmFit,Test)
# Generate confusion matrix
cm <- confusionMatrix(preds, Test$Class, positive = "WS")
# Extract table from cm object
cm_table <- as.data.frame(cm$table)
# Plot and save heatmap with ggplot2
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/confusion_matrix_SVM.png", width = 1000, height = 1000, res = 200)
print(ggplot(cm_table, aes(Prediction, Reference, fill = Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = Freq), size = 6) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = "Confusion Matrix",
x = "Predicted Class",
y = "Actual Class") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14)))
dev.off()
cm
cm$positive
cm$table
cm_table
cm$overall
cm$byClass
cm$dots
cm$mode
cm$overall
cm$overall[1]
# Generate predictions
preds<-predict(svmFit,Test)
# Generate confusion matrix
cm <- confusionMatrix(preds, Test$Class, positive = "WS")
cm
# Extract table from cm object
cm_table <- as.data.frame(cm$table)
# Plot and save heatmap with ggplot2
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/confusion_matrix_SVM.png", width = 1000, height = 1000, res = 200)
print(ggplot(cm_table, aes(Prediction, Reference, fill = Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = Freq), size = 6) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = paste0("Confusion Matrix, Accuracy:",cm$overall[1]),
x = "Predicted Class",
y = "Actual Class") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14)))
dev.off()
# Generate predictions
preds<-predict(svmFit,Test)
# Generate confusion matrix
cm <- confusionMatrix(preds, Test$Class, positive = "WS")
cm
# Extract table from cm object
cm_table <- as.data.frame(cm$table)
# Plot and save heatmap with ggplot2
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/confusion_matrix_SVM.png", width = 1000, height = 1000, res = 200)
print(ggplot(cm_table, aes(Prediction, Reference, fill = Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = Freq), size = 6) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = paste0("Confusion Matrix, Accuracy:",round(cm$overall[1],)),
x = "Predicted Class",
y = "Actual Class") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14)))
dev.off()
# Generate predictions
preds<-predict(svmFit,Test)
# Generate confusion matrix
cm <- confusionMatrix(preds, Test$Class, positive = "WS")
cm
# Extract table from cm object
cm_table <- as.data.frame(cm$table)
# Plot and save heatmap with ggplot2
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/confusion_matrix_SVM.png", width = 1000, height = 1000, res = 200)
print(ggplot(cm_table, aes(Prediction, Reference, fill = Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = Freq), size = 6) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = paste0("Confusion Matrix, Accuracy:",round(cm$overall[1],2)),
x = "Predicted Class",
y = "Actual Class") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14)))
dev.off()
# Read in library and data
library(caret)
data(segmentationData)
# Check for any missing data
length(which(is.na(segmentationData) == TRUE))
# Take a look at what the data looks like
head(segmentationData)
# This code splits our data
trainIndex <- createDataPartition(segmentationData$Class, p = 1/2, list = FALSE, times = 1)
# We assign the 1/2 of data to a training set variable
Train <- segmentationData[ trainIndex,]
# We assign the remaining 1/2 of data to a testing set variable
Test <- segmentationData[-trainIndex,]
# Let's take a look at the dimensions of our training and testing set to see if that all worked out ok
dim(Train)
dim(Test)
# Fit the model
fitControl <- trainControl(method = "repeatedcv", number = 3,repeats = 5)
# Train the model
Fit1 <- train(Class ~ ., data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
# Report the accuracy
Fit1
# Read in necessary libraries
library(dplyr)
# Select the most important variables
Imp <- varImp(Fit1, scale = FALSE)
# Select the top 10 most important features
featSel<-head(rownames(Imp$importance %>% arrange(desc(Overall))), n=10)
# Need to put "+" between all variables
features_string <- paste(featSel, collapse = " + ")
formula_str <- paste("Class ~", features_string)
# Convert string to formula
feat_formula <- as.formula(formula_str)
# Now fit the model with the correct formula
Fit2 <- train(feat_formula, data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
Fit2
# Generate predictions
preds<-predict(Fit2,Test)
# Generate confusion matrix
cm <- confusionMatrix(preds, Test$Class, positive = "WS")
# Extract table from cm object
cm_table <- as.data.frame(cm$table)
# Plot and save heatmap with ggplot2
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/confusion_matrix_RF.png", width = 1000, height = 1000, res = 200)
print(ggplot(cm_table, aes(Prediction, Reference, fill = Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = Freq), size = 6) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = paste0("Confusion Matrix, Accuracy:",round(cm$overall[1],2)),
x = "Predicted Class",
y = "Actual Class") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14)))
dev.off()
# Fit the model
fitControl <- trainControl(
method = "cv",
number = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
#Train the SVM model
svmFit <- train(
Class ~ .,
data = Train,
method = "svmRadial",
trControl = fitControl,
metric = "ROC",
preProcess = c("center", "scale")
)
# Results
print(svmFit)
# Generate predictions
preds<-predict(svmFit,Test)
# Generate confusion matrix
cm <- confusionMatrix(preds, Test$Class, positive = "WS")
cm
# Extract table from cm object
cm_table <- as.data.frame(cm$table)
# Plot and save heatmap with ggplot2
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/confusion_matrix_SVM.png", width = 1000, height = 1000, res = 200)
print(ggplot(cm_table, aes(Prediction, Reference, fill = Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = Freq), size = 6) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = paste0("Confusion Matrix, Accuracy:",round(cm$overall[1],2)),
x = "Predicted Class",
y = "Actual Class") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14)))
dev.off()
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(CognitiveImpairment)
data(package = "AppliedPredictiveModeling")
data( diagnosis)
data(diagnosis)
data(AlzheimerDisease)
head(AlzheimersDisease)
AlzheimerDisease
head(AlzheimerDisease)
head(diagnosis)
head(predictors)
colnames(predictors)
predictors$outcome <- diagnosis
length(which(is.na(predictors) == TRUE))
predictors$outcome <- diagnosis
length(which(is.na(predictors) == TRUE))
# This code splits our data
trainIndex <- createDataPartition(predictors$outcome, p = 2/3, list = FALSE, times = 1)
# We assign the 2/3 of data to a training set variable
Train <- cleanData[ trainIndex,]
predictors$outcome <- diagnosis
length(which(is.na(predictors) == TRUE))
# This code splits our data
trainIndex <- createDataPartition(predictors$outcome, p = 2/3, list = FALSE, times = 1)
# We assign the 2/3 of data to a training set variable
Train <- predictors[ trainIndex,]
# We assign the remaining 1/3 of data to a testing set variable
Test <- predictors[-trainIndex,]
# Let's take a look at the dimensions of our training and testing set to see if that all worked out ok
dim(Train)
dim(Test)
library(caret)
library(glmnet)  # caret will load this via method = "glmnet"
install.packages("glmnet")
library(caret)
library(glmnet)  # caret will load this via method = "glmnet"
set.seed(123)  # For reproducibility
### Define trainControl with bootstrapping resampling
fitControl <- trainControl(
method = "boot",        # bootstrapping
number = 25,            # number of bootstrap samples (you can adjust)
classProbs = TRUE,      # compute class probabilities (helps with some metrics)
summaryFunction = twoClassSummary  # for binary classification metrics like ROC
)
### Train the elastic net model
elasticNetFit <- train(
outcome ~ .,            # formula: predict outcome using all other variables
data = Train,
method = "glmnet",      # elastic net via glmnet
trControl = fitControl,
metric = "ROC",         # optimize model based on ROC AUC (for binary)
preProcess = c("center", "scale"),  # standardize predictors
tuneLength = 10          # number of tuning parameter combinations to try
)
### Inspect model results
print(elasticNetFit)
plot(elasticNetFit)
### Make predictions on Test set
predictions <- predict(elasticNetFit, newdata = Test)
predProbs <- predict(elasticNetFit, newdata = Test, type = "prob")
### Evaluate performance
confMat <- confusionMatrix(predictions, Test$outcome, positive = "demented")
confMat <- confusionMatrix(predictions, Test$outcome)
print(confMat)
library(caret)
library(glmnet)  # caret will load this via method = "glmnet"
set.seed(123)  # For reproducibility
### Define trainControl with bootstrapping resampling
fitControl <- trainControl(
method = "boot",        # bootstrapping
number = 25,            # number of bootstrap samples (you can adjust)
classProbs = TRUE,      # compute class probabilities (helps with some metrics)
summaryFunction = twoClassSummary  # for binary classification metrics like ROC
)
### Train the elastic net model
elasticNetFit <- train(
outcome ~ .,            # formula: predict outcome using all other variables
data = Train,
method = "glmnet",      # elastic net via glmnet
trControl = fitControl,
metric = "ROC",         # optimize model based on ROC AUC (for binary)
preProcess = c("center", "scale"),  # standardize predictors
tuneLength = 10          # number of tuning parameter combinations to try
)
### Inspect model results
print(elasticNetFit)
plot(elasticNetFit)
### Make predictions on Test set
predictions <- predict(elasticNetFit, newdata = Test)
predProbs <- predict(elasticNetFit, newdata = Test, type = "prob")
### Evaluate performance
confMat <- confusionMatrix(predictions, Test$outcome)
print(confMat)
library(pROC)
roc_obj <- roc(Test$outcome, predProbs[, "Impaired"])
plot(roc_obj, main = "ROC Curve")
auc(roc_obj)
library(caret)
cm <- confusionMatrix(predictions, Test$outcome)
fourfoldplot(cm$table)
varImpPlot <- varImp(elasticNetFit)
plot(varImpPlot, top = 20)
plot(varImpPlot, top = 50)
library(PRROC)
install.packages("PRROC")
library(PRROC)
# Assuming predProbs and true labels
pr <- pr.curve(scores.class0 = predProbs[, "Impaired"],
weights.class0 = Test$outcome == "Impaired",
curve = TRUE)
plot(pr)
# Select the most important variables
Imp <- varImp(elasticNetFit, scale = FALSE)
# Select the top 15 most important variables
featSel<-which(Imp$importance$Overall>=10)
# Subset the training set to contain only those variables
featDF<-Train[,featSel]
# Define trainControl with bootstrapping resampling
fitControl <- trainControl(
method = "boot",
number = 25,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
### Train the elastic net model
elasticNetFit <- train(
outcome ~ .,
data = featDF,
method = "glmnet",
trControl = fitControl,
metric = "ROC",
preProcess = c("center", "scale"),
tuneLength = 10
)
featDF
Imp$importance
## Read in libraries
library(caret)
library(glmnet)
## Format the data frame
predictors$outcome <- diagnosis
## Read in libraries
library(caret)
library(glmnet)
library(AppliedPredictiveModeling)
#Read in data
data(AlzheimerDiagnosis)
## Format the data frame
predictors$outcome <- diagnosis
data(AlzheimerDiagnosis)
## Read in libraries
library(caret)
library(glmnet)
library(AppliedPredictiveModeling)
#Read in data
data(AlzheimerDisease)
## Format the data frame
predictors$outcome <- diagnosis
## Check for missing values
length(which(is.na(predictors) == TRUE))
# This code splits our data
trainIndex <- createDataPartition(predictors$outcome, p = 2/3, list = FALSE, times = 1)
# We assign the 2/3 of data to a training set variable
Train <- predictors[ trainIndex,]
# We assign the remaining 1/3 of data to a testing set variable
Test <- predictors[-trainIndex,]
# Let's take a look at the dimensions of our training and testing set to see if that all worked out ok
dim(Train)
dim(Test)
# Define trainControl with bootstrapping resampling
fitControl <- trainControl(
method = "boot",
number = 25,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
### Train the elastic net model
elasticNetFit <- train(
outcome ~ .,
data = Train,
method = "glmnet",
trControl = fitControl,
metric = "ROC",
preProcess = c("center", "scale"),
tuneLength = 10
)
# Inspect model results
print(elasticNetFit)
plot(elasticNetFit)
# Make predictions on Test set
predictions <- predict(elasticNetFit, newdata = Test)
predProbs <- predict(elasticNetFit, newdata = Test, type = "prob")
# Evaluate performance
confMat <- confusionMatrix(predictions, Test$outcome)
print(confMat)
varImpPlot <- varImp(elasticNetFit)
png("/Users/f002yt8/Documents/GitHub/HDS-Foundations_of_Data_Science/Week_5/Lecture_Notes/images/var-imp-plot.png", width = 1000, height = 1000, res = 200)
print(plot(varImpPlot, top = 10))
dev.off()
library(PRROC)
# Assuming predProbs and true labels
pr <- pr.curve(scores.class0 = predProbs[, "Impaired"],
weights.class0 = Test$outcome == "Impaired",
curve = TRUE)
plot(pr)
# Select the top 15 most important variables
featSel<-which(Imp$importance$Overall>=10)
varImpPlot
# Select the top 15 most important variables
featSel<-which(varImpPlot$importance$Overall>=10)
# Subset the training set to contain only those variables
featDF<-Train[,featSel]
# Define trainControl with bootstrapping resampling
fitControl <- trainControl(
method = "boot",
number = 25,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
### Train the elastic net model
elasticNetFit <- train(
outcome ~ .,
data = featDF,
method = "glmnet",
trControl = fitControl,
metric = "ROC",
preProcess = c("center", "scale"),
tuneLength = 10
)
featDF
head(featDF)
featDF$outcome <- diagnosis
featDF$outcome <- Train$outcome
### Train the elastic net model
elasticNetFit <- train(
outcome ~ .,
data = featDF,
method = "glmnet",
trControl = fitControl,
metric = "ROC",
preProcess = c("center", "scale"),
tuneLength = 10
)
# Inspect model results
print(elasticNetFit)
plot(elasticNetFit)
# Make predictions on Test set
predictions <- predict(elasticNetFit, newdata = Test)
predProbs <- predict(elasticNetFit, newdata = Test, type = "prob")
# Evaluate performance
confMat <- confusionMatrix(predictions, Test$outcome)
print(confMat)
# Create example confusion matrix table (replace with your data)
conf_mat <- confusionMatrix(preds, Test$outcome)  # your confusion matrix object
# Create example confusion matrix table (replace with your data)
conf_mat <- confusionMatrix(predictions, Test$outcome)  # your confusion matrix object
# Extract confusion matrix table as data frame
cm_table <- as.data.frame(conf_mat$table)
# Prepare data for plotting:
# Rename columns for clarity
colnames(cm_table) <- c("Prediction", "Reference", "Freq")
# Plot confusion matrix using ggplot2
ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile(color = "black", alpha = 0.8) +       # Create tiles colored by frequency
geom_text(aes(label = Freq), color = "white", size = 6) +  # Add frequency text in tiles
scale_fill_gradient(low = "white", high = "steelblue") +  # Color gradient for tiles
labs(title = "Confusion Matrix",
x = "Actual Class",
y = "Predicted Class") +
theme_minimal() +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14),
plot.title = element_text(size = 16, face = "bold", hjust = 0.5))
